import requests
import pandas as pd
from datetime import datetime, timedelta
from dotenv import load_dotenv
from pytz import timezone
import os

load_dotenv()
API_KEY = os.getenv("API_KEY")

# æ—¥æœ¬ã‚°ãƒ«ãƒ¼ãƒ—
JAPAN_CHANNELS = {
    'åƒ•ãŒè¦‹ãŸã‹ã£ãŸé’ç©º': 'UC-_iQWdEZY66nGGaHH0Ygmg',
    'AKB48': 'UCxjXU89x6owat9dA8Z-bzdw',
    'ä¹ƒæœ¨å‚46': 'UCUzpZpX2wRYOk3J8QTFGxDg',
    'NiziU': 'UCHp2q2i85qt_9nn2H7AvGOw',
    'ME:I': 'UCvTsv4KmVuBdECI08_HR87Q'
}

# éŸ“å›½ã‚°ãƒ«ãƒ¼ãƒ—
KOREA_CHANNELS = {
    'ILLIT': 'UCEpFoWeCMCo5z3EvWaz6hQQ',
    'IVE': 'UC-Fnix71vRP64WXeo0ikd0Q',
    'LE SSERAFIM': 'UCs-QBT4qkj_YiQw1ZntDO3g',
    'Kep1er': 'UC8whlOg70m2Yr3qSMjUhh0g',
    'NewJeans': 'UCMki_UkHb4qSc0qyEcOHHJw'
}

ALL_CHANNELS = {**JAPAN_CHANNELS, **KOREA_CHANNELS}
CSV_FILE = 'youtube_stats.csv'
jst = timezone('Asia/Tokyo')
now = datetime.now(jst)
timestamp = now.strftime('%Y-%m-%dT%H:%M')

expected_columns = ['timestamp'] + list(ALL_CHANNELS.keys())

# CSVèª­ã¿è¾¼ã¿ï¼ˆåˆ—åè£œæ­£ä»˜ãï¼‰
try:
    df = pd.read_csv(CSV_FILE, encoding='utf-8-sig', skipinitialspace=True)
    df['timestamp'] = df['timestamp'].astype(str).str.strip()
    
    if set(df.columns) == set(expected_columns):
        df = df.loc[:, expected_columns]
    else:
        print("âš ï¸ åˆ—æ§‹æˆãŒä¸€è‡´ã—ãªã„ãŸã‚ã€CSVã‚’åˆæœŸåŒ–ã—ã¾ã™")
        df = pd.DataFrame(columns=expected_columns)

except FileNotFoundError:
    df = pd.DataFrame(columns=expected_columns)

# APIã‹ã‚‰å†ç”Ÿæ•°å–å¾—
def get_view_count(channel_id):
    url = f'https://www.googleapis.com/youtube/v3/channels?part=statistics&id={channel_id}&key={API_KEY}'
    response = requests.get(url)
    data = response.json()
    try:
        return int(data['items'][0]['statistics']['viewCount'])
    except (KeyError, IndexError):
        return None

# ä»Šæ—¥ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
new_row = {'timestamp': timestamp}
for name, cid in ALL_CHANNELS.items():
    new_row[name] = get_view_count(cid)

# å·®åˆ†è¨ˆç®—ï¼ˆå‰æ—¥ãƒ»1é€±é–“å‰ï¼‰
diffs_japan = {}
weekly_diffs_japan = {}
diffs_korea = {}
weekly_diffs_korea = {}

today_date = now.strftime('%Y-%m-%d')
yesterday_date = (now - timedelta(days=1)).strftime('%Y-%m-%d')
week_ago_date = (now - timedelta(days=7)).strftime('%Y-%m-%d')

# å‰æ—¥è¡Œã®å–å¾—
yesterday_rows = df[df['timestamp'].str.startswith(yesterday_date)]
yesterday_row = yesterday_rows.iloc[-1] if not yesterday_rows.empty else None

# 1é€±é–“å‰ã®è¡Œã®å–å¾—
week_rows = df[df['timestamp'].str.startswith(week_ago_date)]
week_row = week_rows.iloc[-1] if not week_rows.empty else None

# å·®åˆ†è¨ˆç®—ï¼ˆå‰æ—¥ï¼‰
if yesterday_row is not None:
    for name in JAPAN_CHANNELS.keys():
        if pd.notnull(new_row[name]) and pd.notnull(yesterday_row[name]):
            diffs_japan[name] = new_row[name] - yesterday_row[name]
    for name in KOREA_CHANNELS.keys():
        if pd.notnull(new_row[name]) and pd.notnull(yesterday_row[name]):
            diffs_korea[name] = new_row[name] - yesterday_row[name]

# å·®åˆ†è¨ˆç®—ï¼ˆ1é€±é–“å‰ï¼‰
if week_row is not None:
    for name in JAPAN_CHANNELS.keys():
        if pd.notnull(new_row[name]) and pd.notnull(week_row[name]):
            weekly_diffs_japan[name] = new_row[name] - week_row[name]
    for name in KOREA_CHANNELS.keys():
        if pd.notnull(new_row[name]) and pd.notnull(week_row[name]):
            weekly_diffs_korea[name] = new_row[name] - week_row[name]

# é‡è¤‡é™¤å»ã¨è¿½åŠ ã¯å·®åˆ†è¨ˆç®—ã®å¾Œã«è¡Œã†
today_date = now.strftime('%Y-%m-%d')
df = df[~df['timestamp'].str.startswith(today_date)]
df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)

# 20æ—¥ä»¥ä¸Šå‰ã®è¡Œã‚’å‰Šé™¤
df['timestamp_dt'] = pd.to_datetime(df['timestamp'], errors='coerce')
ten_days_ago = now - timedelta(days=20)
ten_days_ago = ten_days_ago.replace(tzinfo=None)
df = df[df['timestamp_dt'] >= ten_days_ago]
df = df.drop(columns=['timestamp_dt'])

# æ•´å½¢ï¼ˆæ•´æ•°å‹ã¸å¤‰æ›ï¼‰
for name in ALL_CHANNELS.keys():
    df[name] = pd.to_numeric(df[name], errors='coerce').astype('Int64')

# ä¿å­˜ï¼ˆå°æ•°ç‚¹ãªã—ï¼‰
df.to_csv(CSV_FILE, index=False, encoding='utf-8-sig', float_format='%.0f')

# ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤ºï¼ˆæ—¥æœ¬ï¼‰
print(f"\nğŸ“Š {timestamp} ã®æ—¥æœ¬ã‚°ãƒ«ãƒ¼ãƒ—æ—¥åˆ¥å†ç”Ÿæ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
if diffs_japan:
    ranked_japan = sorted(diffs_japan.items(), key=lambda x: x[1], reverse=True)
    for i, (name, diff) in enumerate(ranked_japan, 1):
        status = f"+{int(diff):,}å›" if diff != 0 else "æœªæ›´æ–°"
        print(f"{i}ä½ï¼š{name}ï¼ˆ{status}ï¼‰")
else:
    print("å‰å›ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€æ—¥æœ¬ã‚°ãƒ«ãƒ¼ãƒ—ã®å·®åˆ†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

# æ—¥æœ¬ã‚°ãƒ«ãƒ¼ãƒ—ï¼šé€±å·®ãƒ©ãƒ³ã‚­ãƒ³ã‚°
print(f"\nğŸ“Š {timestamp} ã®æ—¥æœ¬ã‚°ãƒ«ãƒ¼ãƒ—é€±é–“å†ç”Ÿæ•°å·®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆ1é€±é–“å‰ã¨ã®å·®ï¼‰")
if weekly_diffs_japan:
    ranked_week_japan = sorted(weekly_diffs_japan.items(), key=lambda x: x[1], reverse=True)
    for i, (name, diff) in enumerate(ranked_week_japan, 1):
        print(f"{i}ä½ï¼š{name}ï¼ˆ+{int(diff):,}å›ï¼‰")
else:
    print("1é€±é–“å‰ã®ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€æ—¥æœ¬ã‚°ãƒ«ãƒ¼ãƒ—ã®é€±å·®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

# ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤ºï¼ˆéŸ“å›½ï¼‰
print(f"\nğŸ“Š {timestamp} ã®éŸ“å›½ã‚°ãƒ«ãƒ¼ãƒ—æ—¥åˆ¥å†ç”Ÿæ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
if diffs_korea:
    ranked_korea = sorted(diffs_korea.items(), key=lambda x: x[1], reverse=True)
    for i, (name, diff) in enumerate(ranked_korea, 1):
        status = f"+{int(diff):,}å›" if diff != 0 else "æœªæ›´æ–°"
        print(f"{i}ä½ï¼š{name}ï¼ˆ{status}ï¼‰")
else:
    print("å‰å›ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€éŸ“å›½ã‚°ãƒ«ãƒ¼ãƒ—ã®å·®åˆ†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

# éŸ“å›½ã‚°ãƒ«ãƒ¼ãƒ—ï¼šé€±å·®ãƒ©ãƒ³ã‚­ãƒ³ã‚°
print(f"\nğŸ“Š {timestamp} ã®éŸ“å›½ã‚°ãƒ«ãƒ¼ãƒ—é€±é–“å†ç”Ÿæ•°å·®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆ1é€±é–“å‰ã¨ã®å·®ï¼‰")
if weekly_diffs_korea:
    ranked_week_korea = sorted(weekly_diffs_korea.items(), key=lambda x: x[1], reverse=True)
    for i, (name, diff) in enumerate(ranked_week_korea, 1):
        print(f"{i}ä½ï¼š{name}ï¼ˆ+{int(diff):,}å›ï¼‰")
else:
    print("1é€±é–“å‰ã®ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€éŸ“å›½ã‚°ãƒ«ãƒ¼ãƒ—ã®é€±å·®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

print("\nğŸ” å·®åˆ†æ¤œè¨¼ãƒ­ã‚°ï¼ˆæ—¥æœ¬ï¼‰")
if yesterday_row is not None:
    for name in JAPAN_CHANNELS.keys():
        new_val = new_row[name]
        prev_val = yesterday_row[name]
        diff = new_val - prev_val if pd.notnull(new_val) and pd.notnull(prev_val) else 'N/A'
        print(f"{name}: new={new_val}, prev={prev_val}, diff={diff}")
else:
    print("å‰æ—¥ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€æ—¥æœ¬ã‚°ãƒ«ãƒ¼ãƒ—ã®å·®åˆ†æ¤œè¨¼ã¯ã§ãã¾ã›ã‚“ã€‚")

print("\nğŸ” å·®åˆ†æ¤œè¨¼ãƒ­ã‚°ï¼ˆéŸ“å›½ï¼‰")
if yesterday_row is not None:
    for name in KOREA_CHANNELS.keys():
        new_val = new_row[name]
        prev_val = yesterday_row[name]
        diff = new_val - prev_val if pd.notnull(new_val) and pd.notnull(prev_val) else 'N/A'
        print(f"{name}: new={new_val}, prev={prev_val}, diff={diff}")
else:
    print("å‰æ—¥ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€éŸ“å›½ã‚°ãƒ«ãƒ¼ãƒ—ã®å·®åˆ†æ¤œè¨¼ã¯ã§ãã¾ã›ã‚“ã€‚")

print("ğŸ” new_row =", new_row)

print("ğŸ“ ç¾åœ¨ã®ä¿å­˜å…ˆ =", os.path.abspath(CSV_FILE))

print("ğŸ“… timestamp =", timestamp)
print("ğŸ•’ å®Ÿè¡Œæ™‚åˆ» =", datetime.now())

print(f"ğŸ“… å®Ÿè¡Œæ™‚åˆ»ï¼š{timestamp}ï¼ˆæ¨å¥¨ï¼šæ¯æ—¥11:00 JSTä»¥é™ï¼‰")

    
